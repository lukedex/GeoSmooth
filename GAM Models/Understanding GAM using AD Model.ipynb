{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Purpose of this notebook:\n",
    "- Explore GAM models\n",
    "- Build a model and look at the outputs\n",
    "- Look into ways of exporting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install interpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peril_name='PD_Freq'\n",
    "peril_target='Number of PD Claims'\n",
    "#current_model_prediction='PD_Sev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing:\n",
    "    Packages\n",
    "    Data\n",
    "\"\"\"\n",
    "\n",
    "import os as os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import base\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('../Files/downsampled_data.csv')\n",
    "\n",
    "print(\"Packages loaded, dataset read in\")\n",
    "print(\"Current directory is location in:\", os.getcwd())\n",
    "\n",
    "#newpath = f\"{peril_name}_MODEL\\\\\"\n",
    "#if not os.path.exists(newpath):\n",
    "#    os.makedirs(newpath)\n",
    "    \n",
    "#print(f\"New folder called {newpath} created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering / EDA all in one (NOT GOOD PRACTICE BUT IT'S FOR QUICK WORK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FEATURE ENGINEERING:\n",
    "\n",
    "TODO after WTW come back:\n",
    "    XSPIScore needs work\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#Replaces nulls with 0s then label encode of conviction severity\n",
    "labelencoder = LabelEncoder()\n",
    "df['MostSevereConviction'] = df['MostSevereConviction'].fillna(0)\n",
    "df['Conviction_level'] = labelencoder.fit_transform(list(df['MostSevereConviction']))\n",
    "df.drop(\"MostSevereConviction\", axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# MainEmploymentType - Employed (voluntary work, Own Company, Contractor, Independent Means)\n",
    "#, Retired, Sefl Employed, Household Duties, Unemployed, In Full or PArt Time education\n",
    "# Not employed due to disability (Financially Assisted)\n",
    "\n",
    "#OHE: if MainMaritalStatus = 'Married','Common Law','Widowed' then Married, \n",
    "# 'Single' then 'Single'\n",
    "# 'Partnered' , 'Partnered  - Civil'\n",
    "# 'Divorced', 'Seperated'\n",
    "\n",
    "\n",
    "#Changing decline to 0 for all rating columns\n",
    "rating_columns = ['ADRatingArea','FRTHRatingArea','LargeRatingArea','PDRatingArea','PIRatingArea','WSRatingArea']\n",
    "for rating_column in rating_columns:\n",
    "    df[rating_column]=np.where(df[rating_column]==\"DECLINE\", 0, df[rating_column])\n",
    "    df[rating_column]=df[rating_column].fillna(0)\n",
    "    df[rating_column]=df[rating_column].astype(int)\n",
    "\n",
    "# if MainLicenceType = 'FULL' then 1 else 0\n",
    "df[\"licence_full\"] = np.where(df[\"MainLicenceType\"] == \"Full\", 1, 0)\n",
    "\n",
    "df.drop(\"MainLicenceType\", axis=1, inplace=True)\n",
    "#if VehicleKepeper = 'Proposer' then 1 else 0 end as veh_keep_md\n",
    "df[\"Veh_keep_md\"] = np.where(df[\"VehicleKeeper\"] =='Proposer', 1, 0)\n",
    "\n",
    "df.drop(\"VehicleKeeper\", axis=1, inplace=True)\n",
    "#if VehicleOwner = 'Proposer' then 1 else 0 end as veh_own_md\n",
    "df[\"veh_own_md\"] = np.where(df[\"VehicleOwner\"] =='Proposer', 1, 0)\n",
    "df.drop(\"VehicleOwner\", axis=1, inplace=True)\n",
    "#if VehicleType = 'PC' then 1 else 0 end as VehType_PC\n",
    "df[\"veh_type_pc\"] = np.where(df[\"Vehicle Type\"] =='PC', 1, 0)\n",
    "df.drop(\"Vehicle Type\", axis=1, inplace=True)\n",
    "#if Decline_Flag_Banded = 'Acceptable' then 1 else 0 end as Accepted_flag\n",
    "df[\"accepted_flag\"] = np.where(df[\"Decline_Flag_Banded\"] =='Acceptable', 1, 0)\n",
    "df.drop(\"Decline_Flag_Banded\", axis=1, inplace=True)\n",
    "#if MainFullTimeEmployed = 'Y' then 1 else 0 end as FullTimeEmployed_Ind\n",
    "df[\"employed_ind\"] = np.where(df[\"MainFullTimeEmployed\"] =='Y', 1, 0)\n",
    "df.drop(\"MainFullTimeEmployed\", axis=1, inplace=True)\n",
    "#if AddDriverSex = 'M' then 1 else 0 end as AddDriverMale_IND\n",
    "df[\"adddrivermale\"] = np.where(df[\"AddDriverSex\"] =='M', 1, 0)\n",
    "df.drop(\"AddDriverSex\", axis=1, inplace=True)\n",
    "#if Cover = 'Comp' then 1 else 0 end as CoverComp_IND\n",
    "df[\"covercomp\"] = np.where(df[\"Cover\"] =='Comp', 1, 0)\n",
    "df.drop(\"Cover\", axis=1, inplace=True)\n",
    "#if MaindDriverSex = 'M' then 1 else 0 end as MainDriverMale_IND\n",
    "df[\"maindrivermale\"] = np.where(df[\"MainDriverSex\"] =='M', 1, 0)\n",
    "df.drop(\"MainDriverSex\", axis=1, inplace=True)\n",
    "#if NCDProtected = 'Y' then 1 else 0 end as ProtectedNCD_IND \n",
    "df[\"protectedncd\"] = np.where(df[\"NCDProtected\"] =='Y', 1, 0)\n",
    "df.drop(\"NCDProtected\", axis=1, inplace=True)\n",
    "#if ProposerHomeowner = 'Y' then 1 else 0 end as ProposerHomeOwn_IND\n",
    "df[\"proposerhomeown\"] = np.where(df[\"ProposerHomeowner\"] =='Y', 1, 0)\n",
    "df.drop(\"ProposerHomeowner\", axis=1, inplace=True)\n",
    "#if SecondCarFlag = '2nd Car' then 1 else 0 end as SecondCar_IND\n",
    "df[\"SecondCar_IND\"] = np.where(df[\"SecondCarFlag\"] =='2nd Car', 1, 0)\n",
    "df.drop(\"SecondCarFlag\", axis=1, inplace=True)\n",
    "\n",
    "#Drop columns\n",
    "for i in ['MainEmployerBusiness', 'MainOccupation', 'SectorPostcode', 'CoveaRatingArea',\n",
    " 'XSPIRatingArea', 'TransactionType', 'Transaction Type', 'Cancellation_Propensity',\n",
    "         'POS Number', 'Policy Eff Date', 'Transaction Start', 'Transaction End','Exposure Start', 'Exposure End']:\n",
    "    df.drop(i, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify categorical columns (EBMs can use these, but it'd be better to determine what we wnt done with them in future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gams can take categorical features but it's best to figure out what to do with these..\n",
    "\n",
    "num_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_columns = list(df.select_dtypes(include=num_dtypes).columns)\n",
    "categorical_columns = list(df.select_dtypes(exclude=num_dtypes).columns)\n",
    "\n",
    "print(categorical_columns)\n",
    "\n",
    "\"\"\"for delete_for_now in categorical_columns:\n",
    "    df.drop(delete_for_now, axis=1, inplace=True)    \n",
    "    print(delete_for_now, \"deleted.\")\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify how many missings per column and then fill them. The bottom print-out should be empty to show no missings are left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Filling in missings\"\"\"\n",
    "cols_with_missings= df.columns[df.isna().sum()!=0]\n",
    "print(print(df[cols_with_missings].isna().sum()))\n",
    "\n",
    "df.fillna(999, inplace=True)\n",
    "df.fillna(999, inplace=True)\n",
    "print('Next list should be empty to show no missings still remain:')\n",
    "print(df.columns[df.isna().sum()!=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple set of colums picked for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usable_columns = df.drop(columns=['POLICYTRANSACTIONID',\n",
    "     'Unnamed: 0', 'Analysis Year', 'Broker Number', 'Scheme Number', \n",
    "    'Exposure', 'AD Incurred', 'PD Incurred', 'PI Incurred', \n",
    "                    'Large Incurred', 'FR Incurred', 'TH Incurred', 'Small Incurred', \n",
    "                    'WS Incurred', 'Number of AD Claims', 'Number of PD Claims', \n",
    "                    'Number of PD/PI Claims', 'Number of PI Claims', 'Number of Large Claims', \n",
    "                    'Number of FR Claims', 'Number of TH Claims', 'Number of Small Claims', \n",
    "                    'Number of WS Claims', 'AD_Freq', 'AD_Sev', 'PD_Freq', 'PD_Sev', \n",
    "                    'PD_PI_Propensity', 'PI_Sev', 'PI_Large_Propensity', 'Large_Sev', 'FR_Freq', \n",
    "                   'FR_Sev', 'TH_Freq', 'TH_Sev', 'Sm_Freq', 'Sm_Sev', 'WS_Freq', 'WS_Sev', \n",
    "                    'PI_Freq', 'Large_Freq', 'Implementable_AD', 'Implementable_PD', \n",
    "                    'Implementable_PI', 'Implementable_Large', 'Implementable_FRTHSm', \n",
    "                    'Implementable_WS', 'Implementable_Risk_Premium',\n",
    "                    'Policy Number','Theo_XSPI_Group', 'ABICode',\n",
    "                    'adddrivermale','maindrivermale']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Framework\n",
    "#### Just a simple split for now for this test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "df = df.sample(frac = 1) #Shuffle dataframe\n",
    "y = df['Number of PD Claims']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Classification testing - pick up in future\n",
    "#y_train = np.where(y_train > 0, 1, 0)\n",
    "#y_test = np.where(y_test > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of train dataset : ', X_train.shape)\n",
    "print('Shape of the test dataset : ', X_test.shape)\n",
    "print(' Train dataset target information:', y_train.describe())\n",
    "print(' Test dataset target information:', y_test.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run EBM\n",
    "#### Imports interpret package, which has EBM.\n",
    "#### Sets the 'packages' folder which we can read in packages from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '/home/jovyan/Packages/')\n",
    "import useful_functions as uf\n",
    "\n",
    "from interpret.glassbox import ExplainableBoostingRegressor\n",
    "\n",
    "#ExplainableBoostingRegressor()\n",
    "ebm = ExplainableBoostingRegressor(interactions=0, #First model is used for feature selection so no interactions used\n",
    "                                   inner_bags=0, \n",
    "                                   objective='poisson_deviance',\n",
    "                                  smoothing_rounds=0)\n",
    "\n",
    "ebm.fit(X_train.drop(columns=['POLICYTRANSACTIONID',\n",
    "     'Unnamed: 0', 'Analysis Year', 'Broker Number', 'Scheme Number', \n",
    "    'Exposure', 'AD Incurred', 'PD Incurred', 'PI Incurred', \n",
    "                    'Large Incurred', 'FR Incurred', 'TH Incurred', 'Small Incurred', \n",
    "                    'WS Incurred', 'Number of AD Claims', 'Number of PD Claims', \n",
    "                    'Number of PD/PI Claims', 'Number of PI Claims', 'Number of Large Claims', \n",
    "                    'Number of FR Claims', 'Number of TH Claims', 'Number of Small Claims', \n",
    "                    'Number of WS Claims', 'AD_Freq', 'AD_Sev', 'PD_Freq', 'PD_Sev', \n",
    "                    'PD_PI_Propensity', 'PI_Sev', 'PI_Large_Propensity', 'Large_Sev', 'FR_Freq', \n",
    "                   'FR_Sev', 'TH_Freq', 'TH_Sev', 'Sm_Freq', 'Sm_Sev', 'WS_Freq', 'WS_Sev', \n",
    "                    'PI_Freq', 'Large_Freq', 'Implementable_AD', 'Implementable_PD', \n",
    "                    'Implementable_PI', 'Implementable_Large', 'Implementable_FRTHSm', \n",
    "                    'Implementable_WS', 'Implementable_Risk_Premium',\n",
    "                    'Policy Number','Theo_XSPI_Group', 'ABICode',\n",
    "                    'adddrivermale','maindrivermale']), y_train)\n",
    "\n",
    "print(' Train Gini :', uf.gini(y_train, ebm.predict(X_train))) #Note how it can take in additional columns and just ignore them without an error!\n",
    "print(' Validation gini: ', uf.gini(y_test, ebm.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing GAM Changer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gamchanger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.tail(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gamchanger as gc\n",
    "from json import dump\n",
    "\n",
    "# Extract model weights\n",
    "model_data = gc.get_model_data(ebm)\n",
    "\n",
    "# Generate sample data\n",
    "sample_data = gc.get_sample_data(ebm, X_test.tail(2000), y_test.tail(2000))\n",
    "\n",
    "# Save to `model.json` and `sample.json`\n",
    "dump(model_data, open('./model.json', 'w'))\n",
    "dump(sample_data, open('./sample.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gamchanger as gc\n",
    "\n",
    "# Load GAM Changer with the model and sample data\n",
    "gc.visualize(ebm, model_data=model_data, sample_data=sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For info on EBM params from https://interpret.ml/docs/python/api/ExplainableBoostingRegressor.html\n",
    "\n",
    "ExplainableBoostingRegressor(feature_names=None, feature_types=None, max_bins=1024, max_interaction_bins=32, interactions=0.95, exclude=None, validation_size=0.15, outer_bags=14, inner_bags=0, learning_rate=0.01, greedy_ratio=1.5, cyclic_progress=True, smoothing_rounds=200, interaction_smoothing_rounds=50, max_rounds=25000, early_stopping_rounds=50, early_stopping_tolerance=0.0, min_samples_leaf=2, min_hessian=0.0001, max_leaves=3, monotone_constraints=None, objective='rmse', n_jobs=- 2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ebm.monotize() can be used to set monotonic features AFTER the model has been built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ebm.sweep(terms=True, bins=True, features=False) can be used to remove un-used elements within the EBM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a table of feature impotances. \n",
    "##### This mimics the 'summary' of the global visualisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df=pd.DataFrame()\n",
    "feature_importance_df['Feature_Name']=ebm.term_names_\n",
    "feature_importance_df['Importance']=ebm.term_importances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df.sort_values('Importance', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_features=feature_importance_df.head(30)['Feature_Name'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create new model with only top 30 factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm = ExplainableBoostingRegressor(interactions=15, \n",
    "                                   inner_bags=25,\n",
    "                                   outer_bags=25,\n",
    "                                   objective='poisson_deviance',\n",
    "                                  smoothing_rounds=250)\n",
    "ebm.fit(X_train[top_20_features], y_train)\n",
    "\n",
    "print(' Train Gini :', uf.gini(y_train, ebm.predict(X_train))) #Note how it can take in additional columns and just ignore them without an error!\n",
    "print(' Validation gini: ', uf.gini(y_test, ebm.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Visualisation of Global Effects of EBM\n",
    "#### Note: Need to figure out how to download this exactly as is (or something equivalent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret import show\n",
    "from interpret.provider import InlineProvider\n",
    "from interpret import set_visualize_provider\n",
    "\n",
    "set_visualize_provider(InlineProvider())\n",
    "\n",
    "ebm_global = ebm.explain_global(name='EBM')\n",
    "show(ebm_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm_local=ebm.explain_local(X_train.head(1))\n",
    "show(ebm_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to understand EBM's object and create look-up tables with graphs.\n",
    "Taken from https://interpret.ml/docs/ebm-internals-regression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print a list of feature types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ebm.feature_types_in_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print bins used for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ebm.bins_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EBMs also include 2 special bins: the missing bin, and the unknown bin. The missing bin is the bin that we use if there are any feature values that are missing, like NaN or ‘None’. The unknown bin is used whenever we see a categorical value during prediction that was not present in the training set. For example, if our testing dataset had the categorical value “Vietnam”, or “Brazil”, then we would use the unknown bin in this example since those countries did not appear in the training set.\n",
    "\n",
    "The missing bin is always located at the 0th index, and the unknown bin is always at the last index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ebm.term_scores_ contains the lookup tables for each additive term. ebm.term_scores_[0] is the lookup table for the first feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ebm.term_names_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ebm.term_scores_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at intercept used for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ebm.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainset = X_train.drop(columns=['POLICYTRANSACTIONID',\n",
    "     'Unnamed: 0', 'Analysis Year', 'Broker Number', 'Scheme Number', \n",
    "    'Exposure', 'AD Incurred', 'PD Incurred', 'PI Incurred', \n",
    "                    'Large Incurred', 'FR Incurred', 'TH Incurred', 'Small Incurred', \n",
    "                    'WS Incurred', 'Number of AD Claims', 'Number of PD Claims', \n",
    "                    'Number of PD/PI Claims', 'Number of PI Claims', 'Number of Large Claims', \n",
    "                    'Number of FR Claims', 'Number of TH Claims', 'Number of Small Claims', \n",
    "                    'Number of WS Claims', 'AD_Freq', 'AD_Sev', 'PD_Freq', 'PD_Sev', \n",
    "                    'PD_PI_Propensity', 'PI_Sev', 'PI_Large_Propensity', 'Large_Sev', 'FR_Freq', \n",
    "                   'FR_Sev', 'TH_Freq', 'TH_Sev', 'Sm_Freq', 'Sm_Sev', 'WS_Freq', 'WS_Sev', \n",
    "                    'PI_Freq', 'Large_Freq', 'Implementable_AD', 'Implementable_PD', \n",
    "                    'Implementable_PI', 'Implementable_Large', 'Implementable_FRTHSm', \n",
    "                    'Implementable_WS', 'Implementable_Risk_Premium',\n",
    "                    'Policy Number','Theo_XSPI_Group', 'ABICode',\n",
    "                    'adddrivermale','maindrivermale'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Code\n",
    "This code will mimic the .predict() usig params we can save down and disect. Shows it is possible to replicate outside of Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.drop(columns=['POLICYTRANSACTIONID',\n",
    "     'Unnamed: 0', 'Analysis Year', 'Broker Number', 'Scheme Number', \n",
    "    'Exposure', 'AD Incurred', 'PD Incurred', 'PI Incurred', \n",
    "                    'Large Incurred', 'FR Incurred', 'TH Incurred', 'Small Incurred', \n",
    "                    'WS Incurred', 'Number of AD Claims', 'Number of PD Claims', \n",
    "                    'Number of PD/PI Claims', 'Number of PI Claims', 'Number of Large Claims', \n",
    "                    'Number of FR Claims', 'Number of TH Claims', 'Number of Small Claims', \n",
    "                    'Number of WS Claims', 'AD_Freq', 'AD_Sev', 'PD_Freq', 'PD_Sev', \n",
    "                    'PD_PI_Propensity', 'PI_Sev', 'PI_Large_Propensity', 'Large_Sev', 'FR_Freq', \n",
    "                   'FR_Sev', 'TH_Freq', 'TH_Sev', 'Sm_Freq', 'Sm_Sev', 'WS_Freq', 'WS_Sev', \n",
    "                    'PI_Freq', 'Large_Freq', 'Implementable_AD', 'Implementable_PD', \n",
    "                    'Implementable_PI', 'Implementable_Large', 'Implementable_FRTHSm', \n",
    "                    'Implementable_WS', 'Implementable_Risk_Premium',\n",
    "                    'Policy Number','Theo_XSPI_Group', 'ABICode',\n",
    "                    'adddrivermale','maindrivermale'])#.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import softmax\n",
    "\n",
    "sample_scores = []\n",
    "for sample in X:\n",
    "    # start from the intercept for each sample\n",
    "    score = ebm.intercept_#.copy()\n",
    "    if isinstance(score, float) or len(score) == 1:\n",
    "        # regression or binary classification\n",
    "        score = float(score)\n",
    "\n",
    "    # we have multiple terms, so add their score contributions\n",
    "    for term_idx, features in enumerate(ebm.term_features_):\n",
    "        # indexing into a tensor requires a multi-dimensional index\n",
    "        tensor_index = []\n",
    "\n",
    "        # main effects will have 1 feature, and pairs will have 2 features\n",
    "        for feature_idx in features:\n",
    "            feature_val = sample[feature_idx]\n",
    "            bin_idx = 0  # if missing value, use bin index 0\n",
    "\n",
    "            if feature_val is not None and feature_val is not np.nan:\n",
    "                # we bin differently for main effects and pairs, so first \n",
    "                # get the list containing the bins for different resolutions\n",
    "                bin_levels = ebm.bins_[feature_idx]\n",
    "\n",
    "                # what resolution do we need for this term (main resolution, pair\n",
    "                # resolution, etc.), but limit to the last resolution available\n",
    "                bins = bin_levels[min(len(bin_levels), len(features)) - 1]\n",
    "\n",
    "                if isinstance(bins, dict):\n",
    "                    # categorical feature\n",
    "                    # 'unknown' category strings are in the last bin (-1)\n",
    "                    bin_idx = bins.get(feature_val, -1)\n",
    "                else:\n",
    "                    # continuous feature\n",
    "                    try:\n",
    "                        # try converting to a float, if that fails it's 'unknown'\n",
    "                        feature_val = float(feature_val)\n",
    "                        # add 1 because the 0th bin is reserved for 'missing'\n",
    "                        bin_idx = np.digitize(feature_val, bins) + 1\n",
    "                    except ValueError:\n",
    "                        # non-floats are 'unknown', which is in the last bin (-1)\n",
    "                        bin_idx = -1\n",
    "        \n",
    "            tensor_index.append(bin_idx)\n",
    "        # local_score is also the local feature importance\n",
    "        local_score = ebm.term_scores_[term_idx][tuple(tensor_index)]\n",
    "        score += local_score\n",
    "    sample_scores.append(score)\n",
    "\n",
    "predictions = np.exp(np.array(sample_scores))\n",
    "\n",
    "if hasattr(ebm, 'classes_'):\n",
    "    # classification\n",
    "    if len(ebm.classes_) == 2:\n",
    "        # binary classification\n",
    "\n",
    "        # softmax expects two logits for binary classification\n",
    "        # the first logit is always equivalent to 0 for binary classification\n",
    "        predictions = [[0, x] for x in predictions]\n",
    "    predictions = softmax(predictions)\n",
    "\n",
    "if hasattr(ebm, 'classes_'):\n",
    "    print(\"probabilities for classes \" + str(ebm.classes_))\n",
    "    print(\"\")\n",
    "    print(ebm.predict_proba(X))\n",
    "else:\n",
    "    print(ebm.predict(X))\n",
    "print(\"\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.provider import PreserveProvider\n",
    "#set_visualize_provider(PreserveProvider()._preserve_output(explanation_name='test',visual=ebm_global, file='test.html'))\n",
    "\n",
    "from interpret import preserve\n",
    "for key in ebm.term_names_:\n",
    "    preserve(ebm_global, selector_key =key, file_name=f'/home/jovyan/GAM Models/New work/Graphs/{key}.html')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying to work on creating look-up table (or series of look-up tables) for Radar to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm.term_scores_[0]#1st and last are missing and unseen data, middle N items are of len(bins + 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm.bins_[0]#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to find list of featuers and interactions list, starts from 1 and not 0\n",
    "ebm.term_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm.term_names_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the names of the intervals of a level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When it's an interaction names becomes 'left_names' and 'right_names'\n",
    "#ebm_global.data(0)['names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the scores for a level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When it's an interactions scores becaomes an array of lists\n",
    "#ebm_global.data(0)['scores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ebm.term_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#works for numerics\n",
    "for i in range(0,len(ebm.term_features_)):\n",
    "    if len(ebm.term_features_[i]) == 1:\n",
    "        print(f'Term {ebm.term_names_[i]} is a main feature')\n",
    "        num_bins = len(ebm.term_scores_[i])-2\n",
    "        print('  Missing Value bucket:', ebm.term_scores_[i][0])\n",
    "        print('  Unknown Value bucket:', ebm.term_scores_[i][num_bins+1])\n",
    "       \n",
    "\n",
    "    #Checks if the factor is categorical by seeing if the 'bins' is saved as a dictonary rather than an array\n",
    "        if isinstance(ebm.bins_[i][0], dict):\n",
    "            print(f'Term {ebm.term_names_[i]} is categorical')\n",
    "            #Print each bin with\n",
    "            for j in range(0,len(ebm.bins_[i][0])):\n",
    "                print(f' If value = {list(ebm.bins_[i][0].keys())[j]} then {ebm.term_scores_[i][j+1]}')\n",
    "                \n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "        else:\n",
    "            print(f'Term {ebm.term_names_[i]} is numerical')\n",
    "            #Print the first first relativity which is a 'less than first value' \n",
    "            print (f'If {ebm.term_names_[i]} < {ebm.bins_[i][0][0]} then {ebm.term_scores_[i][1]}')\n",
    "            #Print relativities for every interval/bin\n",
    "            for j in range(1,num_bins-1):\n",
    "                print(f'If {ebm.bins_[i][0][j-1]} < {ebm.term_names_[i]} < {ebm.bins_[i][0][j]} then {ebm.term_scores_[i][j+1]}')\n",
    "            #Print relativity for the last relatrivity which is a 'is more than last value'\n",
    "            print (f'If {ebm.term_names_[i]} > {ebm.bins_[i][0][num_bins-2]} then {ebm.term_scores_[i][-2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This interaction code does work but needs to be adapted to check if the feature is categorical or numerical. Easy to take from the above cell though ^"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(columns = ['Factor_1','Value1_low','Value1_high','Factor_2','Value2_low','Value2_high','Score'])\n",
    "\n",
    "factor_1_list=[]\n",
    "value1_low_list=[]\n",
    "value1_high_list=[]\n",
    "factor_2_list=[]\n",
    "value2_low_list=[]\n",
    "value2_high_list=[]\n",
    "score_list=[]\n",
    "\n",
    "for i in range(30,len(ebm.term_features_)): #For each interaction\n",
    "    left_term=ebm.term_features_[i][0]\n",
    "    right_term=ebm.term_features_[i][1]\n",
    "    \n",
    "    # Find the number of different scores for the first factor (i.e left factor unique levels)       \n",
    "    for j in range(1,len(ebm.term_scores_[i])-2):\n",
    "        temp_factor1=ebm.term_names_[left_term]\n",
    "        \n",
    "        \"\"\"\n",
    "        CHECK IF FACTOR IS NUMERICAL OR CATEGORICAL\n",
    "        \"\"\"\n",
    "        \n",
    "        if isinstance(ebm.bins_[i][0], dict):\n",
    "            temp_value1_low= list(ebm.bins_[left_term][0].keys())[j]\n",
    "            temp_value1_high= list(ebm.bins_[left_term][0].keys())[j]\n",
    "        \n",
    "        else: # It is numeric\n",
    "        #Logic to get around the first score being designated to those below the first bound\n",
    "        #Otherwise the score is bin value is returned\n",
    "            if  j==1:\n",
    "                temp_value1_low='lower_bound'\n",
    "            else:\n",
    "                temp_value1_low=ebm.bins_[left_term][1][j-1] \n",
    "    \n",
    "            #Logic to get around the first score being designated to those below the first bound\n",
    "            #Otherwise the score is bin value is returned\n",
    "            if j==len(ebm.term_scores_[i])-3:   \n",
    "                temp_value1_high='upper_bound'\n",
    "            else:\n",
    "                temp_value1_low=ebm.bins_[left_term][1][j] \n",
    "        \n",
    "        \n",
    "    \n",
    "    # For each bin level within left term, find the right term bins\n",
    "            for k in range(1,len(ebm.term_scores_[i][j])-2): \n",
    "                print(k)\n",
    "                #goiw4trjghuiwtrhji needs something logic here douigrtuiog\n",
    "            \n",
    "              \n",
    "                #Right term\n",
    "            temp_factor2=ebm.term_names_[right_term] \n",
    "        \n",
    "        \"\"\" \n",
    "        CHECK IF FACTOR IS NUMERICAL OR CATEGORICAL\n",
    "        \"\"\"\n",
    "            if isinstance(ebm.bins_[i][0], dict):\n",
    "                temp_value1_low= list(ebm.bins_[left_term][0].keys())[j]\n",
    "                temp_value1_high= list(ebm.bins_[left_term][0].keys())[j]\n",
    "                \n",
    "            else: # It is numeric\n",
    "    \n",
    "                if k == 1:            \n",
    "                    temp_value2_low='lower_bound'\n",
    "                else:\n",
    "                    temp_value2_low=ebm.bins_[right_term][1][k-1]                \n",
    "    \n",
    "                if k == len(ebm.term_scores_[i][j])-3: #Minus 3 because we started at 1 and ended at -2 in this loop.\n",
    "                    temp_value2_high='upper_bound'                \n",
    "                else:\n",
    "                    temp_value2_high=ebm.bins_[right_term][1][k]\n",
    "            \n",
    "            # Score for the combination of left and right bin\n",
    "            temp_score=ebm.term_scores_[i][j][k]\n",
    "        \n",
    "        #save result of loop to list\n",
    "        factor_1_list.append(temp_factor1)\n",
    "        value1_low_list.append(temp_value1_low)\n",
    "        value1_high_list.append(temp_value1_high)\n",
    "        factor_2_list.append(temp_factor2)\n",
    "        value2_low_list.append(temp_value2_low)\n",
    "        value2_high_list.append(temp_value2_high)\n",
    "        score_list.append(temp_score)\n",
    "                       \n",
    "                \n",
    "output_df['Factor_1']=factor_1_list\n",
    "output_df['Value1_low']=value1_low_list\n",
    "output_df['Value1_high']=value1_high_list\n",
    "\n",
    "output_df['Factor_2']=factor_2_list\n",
    "output_df['Value2_low']=value2_low_list\n",
    "output_df['Value2_high']=value2_high_list\n",
    "\n",
    "output_df['Score']=score_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm.bins_[\n",
    "    ebm.term_features_[21][0]]#[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm.term_scores_[33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code showing how you can manipulate the plotly figure. In this case it adds on a red line where this prediction falls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
